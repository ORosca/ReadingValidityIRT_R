---
title: "Testlet Response Theory Analysis for IES DAACS Reading Assessment (180 Items), May 2022 - May 2023, umgc1-and-ua2 Combined Sample, AnSamp1, n = 4523"
author: "Oxana Rosca"
date: "`r Sys.Date()`"
output:
  word_document:
    toc: true
    toc_depth: 6
    reference_docx: "C:/Users/orosc/OneDrive - University at Albany - SUNY/My DAACS/WordDocMarkdownTemplate.docx"
  html_document:
    toc: true
    toc_depth: 6 
    theme: readable
---

# Purpose: 
Item Response Theory (IRT) Analysis of DAACS Reading Items Using Bifactor Model. 
IES project, 2022-23, UMGC1 and UA2 Scores, All Items, First Attempt, Non-speedy sts 
(Analytic Sample 1).

# RQ: How well do the 180 reading items fit the 2PL Bifactor IRT model?

# Results: 
the 173-item 2PL-Model pool has acceptable parameters and fits better than the complete
pool of items (k = 180). 
2P-Models fit better than 1PL do; 
7 items with poor a-parameters (< 0.3 and > 4)) and/or b-parameters (> 6) were removed. The remaining 173 items have a good fit to bifactor 2PL IRT model.

# Assessment: 
DAACS Reading Assessment consists of 30 reading passages and 180 dichotomous items (6 items per passage, k = 180). Each respondent answered to 18 items (k_admin = 18 items). For 2022-2023 data-collection via reading assessment, we used a non-adaptive multistage testing design.

# Participants
A total of 5447 participants completed at least one DAACS assessment, including 4152 (76%) from UMGC1 and 1295 (24%) from UA2. All participants had both a DAACS-assigned ID (DAACS_ID) and an institution-assigned ID.
For the reading assessment specifically, 4626 respondents participated: 3894 (84%) from UMGC1 and 732 (16%) from UA2.

## Analytic Sample 1
  Purpose: For IRT analyses.
  Composition: The Analytic Sample 1 (AnSamp1) included 4523 non-speedy respondents: 3798 (84%) from UMGC1 and 725 (16%) from UA2. 
  Data: Collected between May 2022 and May 2023, including all non-speedy respondents' reading scores from their first attempts.
The dataset "read.itemsONLY_AnSamp1" includes 180 items' scores (Q001â€“Q180) but excludes student IDs and other variables.
A detailed dataframe "read.items_AnSamp1" includes 200 columns:180 item scores, 2 ID variables,	18 personal variables, such as reading total scores, dichotomous variables (e.g., gender, age group [below or above 24 years], and college [UMGC or UA2]).  

# R-packages
```{r}
library(car)
library(dplyr)
library(ggplot2)
library(gridExtra)
library(lavaan)
library(maditr)
library(mirt)
library(openxlsx)
library(psych)
library(reshape2)
```

# Data 
"read.items_AnSamp1" (n = 4523) includes the first-attempt scores from non-speedy respondents, who took DAACS Reading assessment in May 2022 - May 2023. 

The df "read.itemsONLY_AnSamp1" includes 180 items' scores (Q001-Q180) and does not contain students' IDs nor other variables.

Load the files with clean data from reading assessment
```{r}
#load("~/Dropbox (Hunter College)/DAACS-Validity/Analyses/dataPrep/read_dataClean-UMGC1UA2_1.RData")
load("C:/Users/orosc/OneDrive - University at Albany - SUNY/My DAACS/read/read_dataClean-UMGC1UA2_1.RData")
#load("E:/OneDrive - University at Albany - SUNY/My DAACS/read/read_dataClean-UMGC1UA2_1.RData")

```

## Analytic Sample 1: 200 columns for 4523 non-speedy sts: 
180 item-scores + 2 ID variables + 18 personal variables: reading total scores, 
dichotomous variables of gender, age (below or above 24 y.o.), and college 
(UMGC or UAlbany), etc., are present in the following dataframe. 
```{r}
# A long self-explanatory title
dim(read.items1stAtt_wide_nsp_umgc1ua2_wPersonal) # 4523  200
# A short title
dim(read.items_AnSamp1) # 4523  200
# Only items' QIDs
dim(read.itemsONLY_AnSamp1) # 4523  180
```

###  College: Numgc1 = 3798 (83.97%), Nua2 = 725 (16.03%) 
```{r} 
read.items_AnSamp1$college %>% table(useNA = "always") %>%
                        prop.table() %>% round(4)
```

## Variable names (QIDs) are in numerical order from Q001 up to Q180:
```{r}
read.itemsONLY_AnSamp1 <- 
  read.itemsONLY_AnSamp1[, sort(names(read.itemsONLY_AnSamp1), 
                                method = "radix")]
# View the updated variable names
names(read.itemsONLY_AnSamp1)
```
### All 180 items are dichotomous
```{r}
n <- nrow(read.itemsONLY_AnSamp1) #people
n <- ncol(read.itemsONLY_AnSamp1) #items
numberOfCategories_tmp <- rep(0,n)
for (j in 1:n) {
	numberOfCategories_tmp[j] <- sum(table(read.itemsONLY_AnSamp1[,j]) >= 0)
}

max(numberOfCategories_tmp)
min(numberOfCategories_tmp)
```

###  All items have from 419 to 500 responses 
```{r}
# read.itemsONLY_AnSamp1.describe <- describe(read.itemsONLY_AnSamp1)

min(read.itemsONLY_AnSamp1.describe$n) # 419
max(read.itemsONLY_AnSamp1.describe$n) # 500
```

## Items' vertical bar charts: counts of correct and wrong answers 
81414 items were responded to by non-speedy students
```{r}
# Subset 180 items and DAACS_ID, AnSample1, n = 4523
read.items1stAtt_wide_AnSamp1 <- 
  read.items_AnSamp1[, c(7, 21:200)] # 4523  181
dim(read.items1stAtt_wide_AnSamp1)
```
Create a LONG item-level file (with a single row for every response.
```{r}
# wide-to-long restructure
# library(reshape2)
read.items1stAtt_long_AnSamp1 <- 
  melt(read.items1stAtt_wide_AnSamp1, id.vars = 'DAACS_ID', 
       na.rm = TRUE) 
names(read.items1stAtt_long_AnSamp1) <- c('DAACS_ID', 'qid', 'score')
dim(read.items1stAtt_long_AnSamp1) # 81414  3
head(read.items1stAtt_long_AnSamp1)
```

Since 180 plots are too many for the given format, create the bar plots in 
console (in Plots plane of R-Studio) and save as "Reading Items Bar Plots 
Correct Responses_AnSamp1.pdf". See "180 Read Items Summary.html" 
for the horizontal bar-plots.
```{r}
#library(ggplot2)

# Ensure score is binary (e.g., TRUE/FALSE or 1/0)
read.items1stAtt_long_AnSamp1$score <- 
  as.logical(read.items1stAtt_long_AnSamp1$score)

#Run in console
ggplot(read.items1stAtt_long_AnSamp1, aes(x = score)) +
  geom_bar() +
  facet_wrap(~ qid, scales = "free_y") + # Adjust scales if necessary
  xlab('Answered Correctly') +
  ylab('Response Count') +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
head(read.items1stAtt_long_AnSamp1)
```

### 81414 responses of non-speedy students: 67124 (82.4%) correct and 14290 wrong, AnSamp1 
The chart includes labels with the exact number of observations on each bar:
```{r}
ggplot(read.items1stAtt_long_AnSamp1, aes(x = as.logical(score))) +
  geom_bar() +
  geom_text(stat = 'count', aes(label = after_stat(count)), vjust = -0.5) + 
  xlab('Answered Correctly') + 
  ylab('')

# Save the plot as a PDF
ggsave(filename = 
  "Reading Items Bar Plot_Total correct and wrong Responses_AnSamp1.pdf")

```

To-do: Function to create stacked bar charts for two groups (colleges) of students 

## 30 Testlets' Empirical plots: DAACS reading was an easy assessment for the sample
The empirical plots of 30 testlets (observed proportions by response input) 
suggested that the DAACS reading was an easy assessment for the sample; there 
were more students that responded to all 6 items of a testlet correctly than 
those that responded correctly to few items.
See the 30 plots in a single image in "Reading Testlets Empirical Plots_observed proportions by response input_AnSamp1.jpg"
```{r}
#library(mirt)

# Define the number of testlets
num_testlets <- 30

# Open a PDF device to save the plots
pdf("Reading Testlets Empirical Plots_observed proportions by response input_AnSamp1.pdf", width = 8, height = 6)

# Create a loop to generate and save plots
for (i in 1:num_testlets) {
  # Define column indices for the current testlet
  start_col_tmp <- (i - 1) * 6 + 1
  end_col_tmp <- i * 6
  
  # Create a dataset for the current testlet
  current_testlet_tmp <- read.itemsONLY_AnSamp1[, start_col_tmp:end_col_tmp]
  
  # Remove rows with missing values
  current_testlet_tmp <- current_testlet_tmp[rowSums(is.na(current_testlet_tmp)) != ncol(current_testlet_tmp), ]
  
  # Build an empirical plot for the current testlet
  empirical_plot_testlet_tmp <- empirical_plot(
    current_testlet_tmp,
    main = paste("Empirical Plot for Testlet Q", start_col_tmp, "- Q", end_col_tmp)
  )
  
  # Print the plot to the PDF
  print(empirical_plot_testlet_tmp)
}

# Close the PDF device
dev.off()
```

### Unidimensionality Tests for Testlets

#### Parallel Tests of Unidimensionality Analyses: 9 testlets were unidimensional
(had one factor), 13 testlets had no general factor, and 8 testlets had more 
than 1 factor.
The testlets models assume every testlet as a single factor. Every testlet
is supposed to be a unidimensional set of 6 items. Parallel analysis (PA) tests
this assumpsion.

The items are organized into testlets by being sorted in ascending order:
```{r}
names(read.itemsONLY_AnSamp1) 
# Check if column names are in increasing order
all(diff(as.numeric(gsub("Q", "", 
                         names(read.itemsONLY_AnSamp1)))) > 0) # TRUE
```

##### Simplified scree-plots in a single chart and the summaries of PA
See the multipanel plot in "Reading Testlets multipanel plot_simplified screeplots_AnSamp1.pdf" (run it in console)
```{r}
# Set up a multi-panel plot
par(mfrow = c(5, 6))  # Adjust these numbers as needed
# Number of testlets
num_testlets <- 30
# Create a loop function for PA
for (i in 1:num_testlets) {
  # Define column indices for the current testlet
  start_col_tmp <- (i - 1) * 6 + 1
  end_col_tmp <- i * 6

  # Create a dataset for the current testlet
  current_testlet_tmp <- read.itemsONLY_AnSamp1[, start_col_tmp:end_col_tmp]

  # Remove rows with missing values
  current_testlet_tmp <- 
    current_testlet_tmp[rowSums(is.na(current_testlet_tmp)) != ncol(current_testlet_tmp), ]

  # Adjust the margins (bottom, left, top, right)
  par(mar = c(2, 1, 2, 1))# Slightly increased top margin for better title placement

  # Perform PA for the current testlet
  read.items_umgc1ua2_parallel_analysis <- 
    fa.parallel(current_testlet_tmp, fm = "ml", fa = "fa", 
                n.iter = 1000, SMC = F, plot = FALSE)

  # Recreate the PA plot without a legend
  plot(read.items_umgc1ua2_parallel_analysis$fa.values, type = "l",
       xlab = "", ylab = "", main = paste("Items Q", start_col_tmp, "-Q", end_col_tmp), 
       cex.main = 1.2, cex.lab = 0.7)
  lines(read.items_umgc1ua2_parallel_analysis$fa.values.simulated, lty = 2)
}

par(mfrow = c(1, 1)) # Switch off the multi-panel plot
dev.off()  # Close current graphics device
```

##### Individual scree plots and detailed eigenvalues
```{r}
# library(psych)
# Number of testlets
num_testlets <- 30
# Create a loop function for PA
	for (i in 1:num_testlets) {
	# Define column indices for the current testlet
			start_col_tmp <- (i - 1) * 6 + 1
			end_col_tmp <- i * 6
	# Create a dataset for the current testlet
			current_testlet_tmp <- read.itemsONLY_AnSamp1[, start_col_tmp:end_col_tmp]
	# Remove rows with missing values
	 current_testlet_tmp <-
	 current_testlet_tmp[rowSums(is.na(current_testlet_tmp)) != ncol(current_testlet_tmp), ]
	# Perform PA for the current testlet
	 read.items_umgc1ua2_parallel_analysis_plot <-
	 	fa.parallel(current_testlet_tmp, fm = "ml", fa = "fa", n.iter = 1000, SMC = F,
		main = paste("Testlet Parallel Analysis, umgc1ua2, items Q", start_col_tmp,
					 "-Q", end_col_tmp))
	# Display the PA plot
	 print(read.items_umgc1ua2_parallel_analysis_plot)}
```

#### 1-Factor CFAs confirmed unidimensionality of 27 testlets and suggested 
non-unidimensionality of the testlets Q019-24, Q103-108, and Q133-138.
RMSEA < 0.05 indicates good fit; 0.05 â‰¤ RMSEA < 0.08 indicates
reasonable fit; RMSEA â‰¥ 0.10 indicates bad fit. RMSEA 90% CI â‰¤ 0.06
indicates a very good fit; RMSEA 90% CI â‰¤ 0.08 indicates a good fit;
RMSEA 90% CI > 0.08 indicates a bad fit;Larger sample sizes provide more
stable estimates and better fit indices.

While the root mean square residual (RMSR) was a measure of the mean
absolute value of the covariance residuals, the standardized root mean
square residual (SRMR) was based on transforming both the sample
covariance matrix and the predicted covariance matrix into correlation
matrices. Smaller values of SRMR (< 0.8 or < 0.9) indicate better fit.
Dr. Colvin: Values of SRMR < 0.08 indicate a good fit.
Dr. Sheu's joint criteria: NNFI or CFI â‰¥ 0.96 and SRMR â‰¤ 0.09;
SRMR â‰¤ 0.09 and RMSEA â‰¤ 0.6
```{r}
# library(lavaan)
Q001Q006m1fcfa<-'read=~Q001+Q002+Q003+Q004+Q005+Q006'# 1-factor model
Q001Q006_read1fCFA<-
  cfa(Q001Q006m1fcfa,data=read.itemsONLY_AnSamp1[,1:6],
                    std.lv=TRUE, orthogonal=FALSE)
summary(Q001Q006_read1fCFA, standardized=TRUE, fit.measures = TRUE)
```

```{r}
Q007Q012m1fcfa<-'read=~Q007+Q008+Q009+Q010+Q011+Q012'
Q007Q012_read1fCFA<-
  cfa(Q007Q012m1fcfa,data=read.itemsONLY_AnSamp1[,7:12],
                    std.lv=TRUE, orthogonal=FALSE)
summary(Q007Q012_read1fCFA, standardized=TRUE, fit.measures = TRUE)
```

```{r}
Q013Q018m1fcfa<-'read=~Q013+Q014+Q015+Q016+Q017+Q018'
Q013Q018_read1fCFA<-
  cfa(Q013Q018m1fcfa,data=read.itemsONLY_AnSamp1[,13:18],
                    std.lv=TRUE, orthogonal=FALSE)
summary(Q013Q018_read1fCFA, standardized=TRUE, fit.measures = TRUE)
```

```{r}
Q019Q024m1fcfa<-'read=~Q019+Q020+Q021+Q022+Q023+Q024'
Q019Q024_read1fCFA<-
  cfa(Q019Q024m1fcfa,data=read.itemsONLY_AnSamp1[,19:24],
                    std.lv=TRUE, orthogonal=FALSE)
summary(Q019Q024_read1fCFA, standardized=TRUE, fit.measures = TRUE)
```

```{r}
Q025Q030m1fcfa<-'read=~Q025+Q026+Q027+Q028+Q029+Q030'
Q025Q030_read1fCFA<-
  cfa(Q025Q030m1fcfa,data=read.itemsONLY_AnSamp1[,25:30],
                    std.lv=TRUE, orthogonal=FALSE)
summary(Q025Q030_read1fCFA, standardized=TRUE, fit.measures = TRUE)
```

```{r}
Q031Q036m1fcfa<-'read=~Q031+Q032+Q033+Q034+Q035+Q036'
Q031Q036_read1fCFA<-
  cfa(Q031Q036m1fcfa,data=read.itemsONLY_AnSamp1[,31:36],
                    std.lv=TRUE, orthogonal=FALSE)
summary(Q031Q036_read1fCFA, standardized=TRUE, fit.measures = TRUE)
```

```{r}
Q037Q042m1fcfa<-'read=~Q037+Q038+Q039+Q040+Q041+Q042'
Q037Q042_read1fCFA<-
  cfa(Q037Q042m1fcfa,data=read.itemsONLY_AnSamp1[,37:42],
                    std.lv=TRUE, orthogonal=FALSE)
summary(Q037Q042_read1fCFA, standardized=TRUE, fit.measures = TRUE)
```

```{r}
Q043Q048m1fcfa<-'read=~Q043+Q044+Q045+Q046+Q047+Q048'
Q043Q048_read1fCFA<-
  cfa(Q043Q048m1fcfa,data=read.itemsONLY_AnSamp1[,43:48],
                    std.lv=TRUE, orthogonal=FALSE)
summary(Q043Q048_read1fCFA, standardized=TRUE, fit.measures = TRUE)
```

```{r}
Q049Q054m1fcfa<-'read=~Q049+Q050+Q051+Q052+Q053+Q054'
Q049Q054_read1fCFA<-
  cfa(Q049Q054m1fcfa,data=read.itemsONLY_AnSamp1[,49:54],
                    std.lv=TRUE, orthogonal=FALSE)
summary(Q049Q054_read1fCFA, standardized=TRUE, fit.measures = TRUE)
```

```{r}
Q055Q060m1fcfa<-'read=~Q055+Q056+Q057+Q058+Q059+Q060'
Q055Q060_read1fCFA<-
  cfa(Q055Q060m1fcfa,data=read.itemsONLY_AnSamp1[,55:60],
                    std.lv=TRUE, orthogonal=FALSE)
summary(Q055Q060_read1fCFA, standardized=TRUE, fit.measures = TRUE)
```

```{r}
Q061Q066m1fcfa<-'read=~Q061+Q062+Q063+Q064+Q065+Q066'
Q061Q066_read1fCFA<-
  cfa(Q061Q066m1fcfa,data=read.itemsONLY_AnSamp1[,61:66],
                    std.lv=TRUE, orthogonal=FALSE)
summary(Q061Q066_read1fCFA, standardized=TRUE, fit.measures = TRUE)
```

```{r}
Q067Q072m1fcfa<-'read=~Q067+Q068+Q069+Q070+Q071+Q072'
Q067Q072_read1fCFA<-
  cfa(Q067Q072m1fcfa,data=read.itemsONLY_AnSamp1[,67:72],
                    std.lv=TRUE, orthogonal=FALSE)
summary(Q067Q072_read1fCFA, standardized=TRUE, fit.measures = TRUE)
```

```{r}
Q073Q078m1fcfa<-'read=~Q073+Q074+Q075+Q076+Q077+Q078'
Q073Q078_read1fCFA<-
  cfa(Q073Q078m1fcfa,data=read.itemsONLY_AnSamp1[,73:78],
                    std.lv=TRUE, orthogonal=FALSE)
summary(Q073Q078_read1fCFA, standardized=TRUE, fit.measures = TRUE)
```

```{r}
Q079Q084m1fcfa<-'read=~Q079+Q080+Q081+Q082+Q083+Q084'
Q079Q084_read1fCFA<-
  cfa(Q079Q084m1fcfa,data=read.itemsONLY_AnSamp1[,79:84],
                    std.lv=TRUE, orthogonal=FALSE)
summary(Q079Q084_read1fCFA, standardized=TRUE, fit.measures = TRUE)
```

```{r}
Q085Q090m1fcfa<-'read=~Q085+Q086+Q087+Q088+Q089+Q090'
Q085Q090_read1fCFA<-
  cfa(Q085Q090m1fcfa,data=read.itemsONLY_AnSamp1[,85:90],
                    std.lv=TRUE, orthogonal=FALSE)
summary(Q085Q090_read1fCFA, standardized=TRUE, fit.measures = TRUE)
```

```{r}
Q091Q096m1fcfa<-'read=~Q091+Q092+Q093+Q094+Q095+Q096'
Q091Q096_read1fCFA<-
  cfa(Q091Q096m1fcfa,data=read.itemsONLY_AnSamp1[,91:96],
                    std.lv=TRUE, orthogonal=FALSE)
summary(Q091Q096_read1fCFA, standardized=TRUE, fit.measures = TRUE)
```

```{r}
Q097Q102m1fcfa<-'read=~Q097+Q098+Q099+Q100+Q101+Q102'
Q097Q102_read1fCFA<-
  cfa(Q097Q102m1fcfa,data=read.itemsONLY_AnSamp1[,97:102],std.lv=TRUE, orthogonal=FALSE)
summary(Q097Q102_read1fCFA, standardized=TRUE, fit.measures = TRUE)
```

```{r}
Q103Q108m1fcfa<-'read=~Q103+Q104+Q105+Q106+Q107+Q108'
Q103Q108_read1fCFA<-
  cfa(Q103Q108m1fcfa,data=read.itemsONLY_AnSamp1[,103:108],
                    std.lv=TRUE, orthogonal=FALSE)
summary(Q103Q108_read1fCFA, standardized=TRUE, fit.measures = TRUE)
```

```{r}
Q109Q114m1fcfa<-'read=~Q109+Q110+Q111+Q112+Q113+Q114'
Q109Q114_read1fCFA<-
  cfa(Q109Q114m1fcfa,data=read.itemsONLY_AnSamp1[,109:114],
                    std.lv=TRUE, orthogonal=FALSE)
summary(Q109Q114_read1fCFA, standardized=TRUE, fit.measures = TRUE)
```

```{r}
Q115Q120m1fcfa<-'read=~Q115+Q116+Q117+Q118+Q119+Q120'
Q115Q120_read1fCFA<-
  cfa(Q115Q120m1fcfa,data=read.itemsONLY_AnSamp1[,115:120],
                    std.lv=TRUE, orthogonal=FALSE)
summary(Q115Q120_read1fCFA, standardized=TRUE, fit.measures = TRUE)
```

```{r}
Q121Q126m1fcfa<-'read=~Q121+Q122+Q123+Q124+Q125+Q126'
Q121Q126_read1fCFA<-
  cfa(Q121Q126m1fcfa,data=read.itemsONLY_AnSamp1[,121:126],
                    std.lv=TRUE, orthogonal=FALSE)
summary(Q121Q126_read1fCFA, standardized=TRUE, fit.measures = TRUE)
```

```{r}
Q127Q132m1fcfa<-'read=~Q127+Q128+Q129+Q130+Q131+Q132'
Q127Q132_read1fCFA<-
  cfa(Q127Q132m1fcfa,data=read.itemsONLY_AnSamp1[,127:132],
                    std.lv=TRUE, orthogonal=FALSE)
summary(Q127Q132_read1fCFA, standardized=TRUE, fit.measures = TRUE)
```

```{r}
Q133Q138m1fcfa<-'read=~Q133+Q134+Q135+Q136+Q137+Q138'
Q133Q138_read1fCFA<-
  cfa(Q133Q138m1fcfa,data=read.itemsONLY_AnSamp1[,133:138],
                    std.lv=TRUE, orthogonal=FALSE)
summary(Q133Q138_read1fCFA, standardized=TRUE, fit.measures = TRUE)
```

```{r}
Q139Q144m1fcfa<-'read=~Q139+Q140+Q141+Q142+Q143+Q144'
Q139Q144_read1fCFA<-
  cfa(Q139Q144m1fcfa,data=read.itemsONLY_AnSamp1[,139:144],
                    std.lv=TRUE, orthogonal=FALSE)
summary(Q139Q144_read1fCFA, standardized=TRUE, fit.measures = TRUE)
```

```{r}
Q145Q150m1fcfa<-'read=~Q145+Q146+Q147+Q148+Q149+Q150'
Q145Q150_read1fCFA<-
  cfa(Q145Q150m1fcfa,data=read.itemsONLY_AnSamp1[,145:150],
                    std.lv=TRUE, orthogonal=FALSE)
summary(Q145Q150_read1fCFA, standardized=TRUE, fit.measures = TRUE)
```

```{r}
Q151Q156m1fcfa<-'read=~Q151+Q152+Q153+Q154+Q155+Q156'
Q151Q156_read1fCFA<-
  cfa(Q151Q156m1fcfa,data=read.itemsONLY_AnSamp1[,151:156],
                    std.lv=TRUE, orthogonal=FALSE)
summary(Q151Q156_read1fCFA, standardized=TRUE, fit.measures = TRUE)
```

```{r}
Q157Q162m1fcfa<-'read=~Q157+Q158+Q159+Q160+Q161+Q162'
Q157Q162_read1fCFA<-
  cfa(Q157Q162m1fcfa,data=read.itemsONLY_AnSamp1[,157:162],
                    std.lv=TRUE, orthogonal=FALSE)
summary(Q157Q162_read1fCFA, standardized=TRUE, fit.measures = TRUE)
```

```{r}
Q163Q168m1fcfa<-'read=~Q163+Q164+Q165+Q166+Q167+Q168'
Q163Q168_read1fCFA<-
  cfa(Q163Q168m1fcfa,data=read.itemsONLY_AnSamp1[,163:168],
                    std.lv=TRUE, orthogonal=FALSE)
summary(Q163Q168_read1fCFA, standardized=TRUE, fit.measures = TRUE)
```

```{r}
Q169Q174m1fcfa<-'read=~Q169+Q170+Q171+Q172+Q173+Q174'
Q169Q174_read1fCFA<-
  cfa(Q169Q174m1fcfa,data=read.itemsONLY_AnSamp1[,169:174],
                    std.lv=TRUE, orthogonal=FALSE)
summary(Q169Q174_read1fCFA, standardized=TRUE, fit.measures = TRUE)
```

```{r}
Q175Q180m1fcfa<-'read=~Q175+Q176+Q177+Q178+Q179+Q180'
Q175Q180_read1fCFA<-
  cfa(Q175Q180m1fcfa,data=read.itemsONLY_AnSamp1[,175:180],
                    std.lv=TRUE, orthogonal=FALSE)
summary(Q175Q180_read1fCFA, standardized=TRUE, fit.measures = TRUE)
```

### Students Overlap across 30 Testlets: range of 17-500 students per pair of testlets 
All sets are interconnected by more than 16 common test-takers (range of 17-500) 
An important requirement of a concurrent IRT analysis of several Testlets
is to have common students-test-takers for each pair of sets of items.
To test this requirement, create an item-sample dataframe with 30 items that
represent 30 unidimensional sets. For example, sample the first item from each
set of items.
```{r}
# Create a vector with the item IDs for the first items of 30 testlets
readTestlet_1stItem_vector_num <- seq(1, 180, 6)
readTestlet_1stItem_vector <- sprintf("Q%03d",readTestlet_1stItem_vector_num)
readTestlet_1stItem_vector_num
readTestlet_1stItem_vector
```

```{r}
# Create an empty matrix to store the results
read.items_AnSamp1umgc1ua2_ItemStudentOverlap_matrix <- 
 matrix(0,nrow=ncol(read.itemsONLY_AnSamp1[,c(readTestlet_1stItem_vector_num)]), 
      ncol = ncol(read.itemsONLY_AnSamp1[, c(readTestlet_1stItem_vector_num)]))
# Iterate through each combination of items and count how many students responded 
# to both items
for(i in 1:ncol(read.itemsONLY_AnSamp1[,c(readTestlet_1stItem_vector_num)])){
  for(j in 1:ncol(read.itemsONLY_AnSamp1[,c(readTestlet_1stItem_vector_num)])){
    # Count how many students responded to both items (excluding NA values)
    read.items_AnSamp1umgc1ua2_ItemStudentOverlap_matrix[i, j] <- 
  sum(!is.na(read.itemsONLY_AnSamp1[, c(readTestlet_1stItem_vector_num)][,i])&!
        is.na(read.itemsONLY_AnSamp1[, c(readTestlet_1stItem_vector_num)][,j]))
  }
}
read.items_AnSamp1umgc1ua2_ItemStudentOverlap_matrix
```

```{r}
min(read.items_AnSamp1umgc1ua2_ItemStudentOverlap_matrix) # 17
max(read.items_AnSamp1umgc1ua2_ItemStudentOverlap_matrix) # 500
```

```{r}
# Convert the matrix to a data frame with row and column names
read.items_AnSamp1umgc1ua2_ItemStudentOverlap_matrix <- 
  as.data.frame(read.items_AnSamp1umgc1ua2_ItemStudentOverlap_matrix)
rownames(read.items_AnSamp1umgc1ua2_ItemStudentOverlap_matrix) <- 
  colnames(read.itemsONLY_AnSamp1[, c(readTestlet_1stItem_vector_num)])
colnames(read.items_AnSamp1umgc1ua2_ItemStudentOverlap_matrix) <- 
  colnames(read.itemsONLY_AnSamp1[, c(readTestlet_1stItem_vector_num)])
read.items_AnSamp1umgc1ua2_ItemStudentOverlap_matrix
write.csv(read.items_AnSamp1umgc1ua2_ItemStudentOverlap_matrix,
          "read.items_AnSamp1umgc1ua2_TestletStudentOverlap_matrix.csv")
```

# Testlet Response Theory (TRT) Analyses of Reading Items
```{r}
# Create a DAACS_ID vector 
read.items_AnSamp1DAACS_ID_vector<-read.items_AnSamp1$DAACS_ID
# Create a string vector to organize items into testlets 
readTestletModelVector <- rep(paste("Set", 1:30), each = 6)
readTestletModelVector
# Create a numeric vector to organize items into testlets 
readTestletModelVector_num <- rep(1:30, each = 6)
readTestletModelVector_num
```

## All-180-Reading-Items Bifactor Models: 2PL fits better than 1PL  
The 2PL model fits better than the 1PL model for the 180 reading items.

### 1PL readBifactor model 
```{r}
# readBifactor1PL_180<-
#   bfactor(read.itemsONLY_AnSamp1,readTestletModelVector_num,
#                          itemtype = 'Rasch', TOL = 1e-03,
#                          SE = TRUE,
#                          accelerate = 'none',
#                          technical = list(NCYCLES = 2000))
# extract.mirt(readBifactor1PL_180,"converged") # has the model converged?
readBifactor1PL_180
```

### 2PL readBifactor model fits better 
```{r}
# readBifactor2PL_180<-
#   bfactor(read.itemsONLY_AnSamp1,readTestletModelVector_num,
#                          itemtype = '2PL', TOL = 1e-03,
#                          SE = TRUE,
#                          accelerate = 'none',
#                          technical = list(NCYCLES = 2000))
# extract.mirt(readBifactor2PL_180,"converged")
readBifactor2PL_180
```

#### ANOVA for nested models: 2PL Model fits better than 1PL 
(the 3PLs didn't run/invert) 
```{r}
anova(readBifactor1PL_180,readBifactor2PL_180)
```

#### Local Dependency Residuals Summaries for 180 Reading Items (2PLModel-based)
Standardized values of Ï‡2 and G2 (upper diagonal) should be below 0.1.
Phil Chalmers "... that advice does come from my experiences, and similar
cutoffs have been proposed in the linear factor analysis literature when
inspecting standardized residuals."
```{r}
readBifactor2PL_180_ResidualsLDX2<-residuals(readBifactor2PL_180,QMC=TRUE)
```

```{r}
readBifactor2PL_180_ResidualsLDG2<-
  residuals(readBifactor2PL_180,QMC=TRUE,type="LDG2")
```

type = Q3 Does not work with missing values of the multistage testing (90% 
of data)
```{r}
# readBifactor2PL_180_ResidualsQ3<-residuals(readBifactor2PL_180,type='Q3')
```

Save the files
```{r}
#library(openxlsx)
write.xlsx(readBifactor2PL_180_ResidualsLDX2, 
           file = "readBifactor2PL_180_ResidualsLDX2.xlsx", rowNames = TRUE)
write.xlsx(readBifactor2PL_180_ResidualsLDG2, 
           file = "readBifactor2PL_180_ResidualsLDG2.xlsx", rowNames = TRUE)
```

#### Theta scores (F-scores in "mirt" package ) are negatively skewed.
Probable Reasons for skewed distribution of thetas:
- Non-Adaptive Format:
Non-adaptive tests may have many items that are either too easy or too hard for 
test-takers, leading to less precise measurement and skewed theta distributions.
Reference: Weiss, D. J. (2011). Better data from better measurements using 
computerized adaptive testing. Journal of Methods and Measurement in the Social 
Sciences, 2(1), 1â€“27. Key Insight: Highlights the limitations of non-adaptive 
testing and its impact on measurement precision.
- Uniform Difficulty:
If item difficulties are not well-matched to the ability range of test-takers, 
the resulting theta estimates can cluster at one end, leading to skewness.
Reference: Baker, F. B. (2001). The Basics of Item Response Theory (2nd ed.). 
ERIC Clearinghouse. Key Insight: Explains how a mismatch in item difficulty 
affects the distribution of ability estimates.
- Bifactor Testlet IRT:
The bifactor model accounts for general and specific factors but introduces 
local dependencies that can skew distributions if passage-specific variances 
are significant. Reference: Gibbons, R. D., & Hedeker, D. R. (1992). Full-
information item bifactor analysis. Psychometrika, 57(3), 423â€“436. Key Insight: 
Discusses how the bifactor model operates and its potential limitations, 
including local dependencies

##### M = 0.0001, SD = 0.81
Central tendency characteristics of the theta scores for the 180 reading items
```{r}
Theta_read180<-fscores(readBifactor2PL_180,method="EAP", QMC=TRUE, 
          full.scores=TRUE,full.scores.SE=TRUE)
# Ensure the data is in a data frame format
Theta_read180 <- data.frame(Theta_read180)

# Add the variable of DAACS_ID to the dataframe with thetas:
Theta_read180$DAACS_ID <- read.items_AnSamp1DAACS_ID_vector
# Rename the columns
names(Theta_read180)[1] <- "Theta_read180"
names(Theta_read180)[32] <- "SE_Theta_read180"
names(Theta_read180)
```

Save theta estimates to external file
```{r}
write.csv(Theta_read180,
          "Theta_read180.csv",quote=F,row.names=F)
# Calculate mean and standard deviation
mean_valueThetas_180 <- mean(Theta_read180$Theta_read180, na.rm = TRUE)
sd_valueThetas_180 <- sd(Theta_read180$Theta_read180, na.rm = TRUE)
mean_valueThetas_180 # 0.0001
sd_valueThetas_180 # 0.81
```

#### Parameters for 180 Reading Items (2PLModel-based) 
Warning message: Traditional parameterization (using IRTpars = TRUE) only 
available for unidimensional models or models with simple structure patterns 
(neither found). 
```{r}
# \dontrun{} tmp<- coef(readBifactor2PL_180,as.data.frame = TRUE, 
#                                     IRTpars = TRUE, printSE = TRUE)
```

a = discrimination; aG = general a-parameter, aS = specific a-parameter.
d = intercept: It's the logit value which a person with theta = 0 has of 
answering the item. So if d = 1, then plogis(1) = .73, while if d = -1, then 
plogis(-1) = .26.
```{r}
tmp<- coef(readBifactor2PL_180,as.data.frame = TRUE, printSE = TRUE)
tmp<-round(tmp, 2)
tmp <- subset(tmp[complete.cases(tmp),])
# Extract rownames based on the pattern
d_rows_tmp <- rownames(tmp[grep("\\.d$", rownames(tmp)), ])
aG_rows_tmp <- rownames(tmp[grep("\\.a1$", rownames(tmp)), ])
other_rows_tmp <- rownames(tmp[!(grepl("\\.d$|\\.a1$", rownames(tmp))), ])
# Create temporary data frames for each category
tmp_d <- tmp[d_rows_tmp, c("par", "SE")]
tmp_aG <- tmp[aG_rows_tmp, c("par", "SE")]
tmp_other <- tmp[other_rows_tmp, c("par", "SE")]
# Create the result matrix
result_matrix_tmp <- 
  matrix(NA,nrow=max(length(d_rows_tmp),length(aG_rows_tmp),
                     length(other_rows_tmp)),ncol=9)
rownames(result_matrix_tmp) <- 1:nrow(result_matrix_tmp)
# Fill the result matrix with data from temporary data frames
result_matrix_tmp[1:nrow(tmp_d), c(7, 8, 9)] <- cbind(d_rows_tmp, tmp_d)
result_matrix_tmp[1:nrow(tmp_aG), c(1, 2, 3)] <- cbind(aG_rows_tmp, tmp_aG)
result_matrix_tmp[1:nrow(tmp_other), c(4, 5, 6)] <- 
  cbind(other_rows_tmp, tmp_other)
# Sort the rows in each category
result_matrix_tmp <- result_matrix_tmp[order(result_matrix_tmp[, 1]), ]
colnames(result_matrix_tmp)<- c("qid","aG", "SE_aG",
                            "qid.a_testlet", "aS", "SE_aS",
                            "qid.d", "d", "SE_d")
# Print the resulting matrix
readBifactor2PL_180_Parameters<-print(result_matrix_tmp)
readBifactor2PL_180_Parameters
write.table(readBifactor2PL_180_Parameters,
            'readBifactor2PL_180_Parameters.csv',sep=',')
```

###### aG-parameters: min = 0.01, max = 8.49; SE [0.13, 8.46] 
```{r}
readBifactor2PL_180_Parameters<-as.data.frame(readBifactor2PL_180_Parameters)
# convert the parameters into numerical variables
numeric_cols_tmp <- c(2, 3, 5, 6, 8, 9)
readBifactor2PL_180_Parameters[numeric_cols_tmp] <- 
  sapply(readBifactor2PL_180_Parameters[numeric_cols_tmp], as.numeric)
range(readBifactor2PL_180_Parameters$aG, na.rm = TRUE)
range(readBifactor2PL_180_Parameters$SE_aG, na.rm = TRUE)
range(readBifactor2PL_180_Parameters$b, na.rm = TRUE)
```

##### Boxplots for item parameters and their SEs
```{r}
# Load necessary libraries
library(ggplot2)
library(gridExtra)

# Create individual boxplots
plot_tmp1 <- ggplot(data = readBifactor2PL_180_Parameters, aes(y = aG)) +
  geom_boxplot(fill = "grey", color = "black") +
  labs(y = "aG-Parameters (General Factor)") +
  theme_minimal()

plot_tmp2 <- ggplot(data = readBifactor2PL_180_Parameters, aes(y = SE_aG)) +
  geom_boxplot(fill = "grey", color = "black") +
  labs(y = "Standard Errors for aG-Parameters") +
  theme_minimal()

plot_tmp3 <- ggplot(data = readBifactor2PL_180_Parameters, aes(y = aS)) +
  geom_boxplot(fill = "grey", color = "black") +
  labs(y = "aS-Parameters (Testlet Scores)") +
  theme_minimal()

plot_tmp4 <- ggplot(data = readBifactor2PL_180_Parameters, aes(y = SE_aS)) +
  geom_boxplot(fill = "grey", color = "black") +
  labs(y = "Standard Errors for aS-Parameters") +
  theme_minimal()

plot_tmp5 <- ggplot(data = readBifactor2PL_180_Parameters, aes(y = d)) +
  geom_boxplot(fill = "grey", color = "black") +
  labs(y = "d-Parameters (Intercept)") +
  theme_minimal()

plot_tmp6 <- ggplot(data = readBifactor2PL_180_Parameters, aes(y = SE_d)) +
  geom_boxplot(fill = "grey", color = "black") +
  labs(y = "Standard Errors for d-Parameters") +
  theme_minimal()

# Compute b-parameters and add the boxplot
readBifactor2PL_180_Parameters$b <- -readBifactor2PL_180_Parameters$d /
  sqrt(readBifactor2PL_180_Parameters$aG^2 + 
         readBifactor2PL_180_Parameters$aS^2)

plot_tmp7 <- ggplot(data = readBifactor2PL_180_Parameters, aes(y = b)) +
  geom_boxplot(fill = "grey", color = "black") +
  labs(y = "b-Parameters (MDIFF)") +
  theme_minimal()

plot_tmp8 <- ggplot(data = read.itemsONLY_AnSamp1.describe, aes(y = mean)) +
  geom_boxplot(fill = "grey", color = "black") +
  labs(y = "Items' Mean Values") +
  theme_minimal()

# Combine the plots into a single layout
readbifactor2PL_AnSamp1_paramBoxplots <- 
  grid.arrange(plot_tmp1, plot_tmp2, plot_tmp3, plot_tmp4, plot_tmp5, plot_tmp6, plot_tmp7, plot_tmp8, ncol = 2)

# Save to PDF
pdf("readbifactor2PL_AnSamp1_paramBoxplots.pdf", width = 10, height = 12)
grid.arrange(plot_tmp1, plot_tmp2, plot_tmp3, plot_tmp4, plot_tmp5, plot_tmp6, plot_tmp7, plot_tmp8, ncol = 2)
dev.off()

```

#### Total explained variance accounted for by the general factor is 62.9%
The proportion of explained common variance (ECV) provides an estimate of how
much variance in item responses is explained by the general factor, as opposed
to specific factors. 
```{r}
# Extract Item aG-Parameters and calculate the variance accounted for the general 
# factor by squaring the factor loadings. The squared loadings represent the 
# proportion of each item's variance that is explained by the respective factor.
readBifactor2PL_180_Parameters_df<-as.data.frame(readBifactor2PL_180_Parameters)
numeric_cols_tmp <- c(2, 3, 5, 6, 8, 9) # to convert the loadings into numeric form
readBifactor2PL_180_Parameters_df[numeric_cols_tmp] <- 
  sapply(readBifactor2PL_180_Parameters_df[numeric_cols_tmp], as.numeric)
str(readBifactor2PL_180_Parameters_df)
readBifactor2PL_180_loadings<-readBifactor2PL_180_Parameters_df[,c(2,5)]
squared_loadings_tmp <- (readBifactor2PL_180_loadings)^2

# Sum the squared loadings for the general factor across all items to get the 
#total variance accounted for by the general factor. You can do the same for 
#each specific factor.
general_factor_variance_tmp <- sum(squared_loadings_tmp[,1])

# Total variance (sum of squared loadings for all factors)
total_variance_tmp <- rowSums(squared_loadings_tmp)

# Proportion of Explained Common Variance (ECV)
ECVreadBifactor2PL_180 <- general_factor_variance_tmp / sum(total_variance_tmp)

# Print the ECV
print(ECVreadBifactor2PL_180) # 0.6287909
```

#### Items' IRT Plots 
see "Reading Items IRT Plots_AnSamp1.pdf"
```{r}
# To see the plots in the plots pane only:
# Loop through each item, generate and display the plot
for(i in 1:180) {
  # Generate the plot
  readbifactor2PL_AnSamp1_180irtPlots <- 
    itemplot(readBifactor2PL_180, i, drop.zeros = TRUE)
  
  # Explicitly print the plot
  print(readbifactor2PL_AnSamp1_180irtPlots)
}

# To save the plots in a PDF file:
# Open a PDF file to save all plots
pdf("180 Reading Items IRT Plots_AnSamp1.pdf")

# Loop through each item and generate a plot
for(i in 1:180) {
  # Generate the plot
  # readbifactor2PL_AnSamp1_180irtPlots <- 
  # itemplot(readBifactor2PL_180, i, drop.zeros = TRUE)
  
  # Explicitly print the plot to the PDF
  print(readbifactor2PL_AnSamp1_180irtPlots)
}
# Close the PDF device
dev.off()
```

## 172-Reading-Item Bifactor Models hang. 
Do not run.

### Remove 8 items with poor aG-parameters: < 0.3 and > 4
```{r} 
# read.items_172_umgc1ua2 <- 
#   read.itemsONLY_AnSamp1 %>%
#   select(-c(Q009, Q010, Q050, Q083, Q108, Q122, Q161, Q172))
# 
# # Create a numeric vector to organize items into testlets 
# readTestletModelVector_172 <- c(1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  3,  
# 3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  6,  6,  6,  
# 6,  6,  6,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9, 
# 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 13, 13, 
# 13, 13, 13, 13, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 
# 16, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 20, 20, 
# 20, 20, 20, 20, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23, 
# 23, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 27, 
# 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 30)
```

readBifactor 1PL model cant pass 236 iterations (hangs)
```{r} 
# readBifactor1PL_172<-bfactor(read.items_172_umgc1ua2,readTestletModelVector_172,
#                              itemtype = 'Rasch', TOL = 1e-03,
#                              SE = TRUE,
#                              accelerate = 'none',
#                              technical = list(NCYCLES = 2000))
# extract.mirt(readBifactor1PL_172,"converged")
# readBifactor1PL_172
```

readBifactor 2PL model cant pass 222 iterations (hangs)
```{r} 
# readBifactor2PL_172<-bfactor(read.items_172_umgc1ua2,readTestletModelVector_172,
#                              itemtype = '2PL', TOL = 1e-03,
#                              SE = TRUE,
#                              accelerate = 'none',
#                              technical = list(NCYCLES = 2000))
# extract.mirt(readBifactor2PL_172,"converged")
# readBifactor2PL_172
```

## 173-Reading-Item Bifactor Models fit better than 180-item models 

### Remove 7 items with poor aG parameters(< 0.1 and > 4) but retain Q010 (aG = 0.1)
```{r}
# library(maditr)
# library(dplyr)
read.items_173_umgc1ua2 <- 
  read.itemsONLY_AnSamp1 %>%
  select(-c(Q009, Q050, Q083, Q108, Q122, Q161, Q172))
```

The items are organized into testlets by being sorted in ascending order:
```{r}
names(read.items_173_umgc1ua2) 
# Check if column names are in increasing order
all(diff(as.numeric(gsub("Q", "", names(read.items_173_umgc1ua2)))) > 0) # TRUE
```

Create a numeric vector to organize items into testlets
```{r}
readTestletModelVector_173 <- c(1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  3,  
3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  6,  6,  6,  
6,  6,  6,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9, 
10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 13, 13, 
13, 13, 13, 13, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 
16, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 20, 20, 
20, 20, 20, 20, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23, 
23, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 27, 
27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 30, 30, 30, 30,30,30)
```

### 1PL readBifactor model
```{r}
# readBifactor1PL_173<-
#   bfactor(read.items_173_umgc1ua2,readTestletModelVector_173,
#                              itemtype = 'Rasch', TOL = 1e-03,
#                              SE = TRUE,
#                              accelerate = 'none',
#                              technical = list(NCYCLES = 2000))
# extract.mirt(readBifactor1PL_173,"converged")
readBifactor1PL_173
```

### 2PL readBifactor model fits better 
```{r}
# readBifactor2PL_173<-
#   bfactor(read.items_173_umgc1ua2,readTestletModelVector_173,
#                              itemtype = '2PL', TOL = 1e-03,
#                              SE = TRUE,
#                              accelerate = 'none',
#                              technical = list(NCYCLES = 2000))
# extract.mirt(readBifactor2PL_173,"converged")
readBifactor2PL_173
```

#### ANOVA for nested models: 2PL Model fits better than 1PL 
```{r}
anova(readBifactor1PL_173,readBifactor2PL_173)
```

#### Model comparison for non-nested models: 173-item Model fits better than 180-item model
```{r}
anova(readBifactor2PL_180,readBifactor2PL_173)
```


#### Local Dependency Residuals Summaries for 173 Reading Items (2PLModel-based)
Standardized values of Ï‡2 and G2 (upper diagonal) should be below 0.1.
Phil Chalmers "... that advice does come from my experiences, and similar
cutoffs have been proposed in the linear factor analysis literature when
inspecting standardized residuals."
```{r}
readBifactor2PL_173_ResidualsLDX2<-residuals(readBifactor2PL_173,QMC=TRUE)
```

```{r}
readBifactor2PL_173_ResidualsLDG2<-
  residuals(readBifactor2PL_173,QMC=TRUE,type="LDG2")
```

```{r}
write.xlsx(readBifactor2PL_173_ResidualsLDX2, 
           file = "readBifactor2PL_173_ResidualsLDX2.xlsx", rowNames = TRUE)
write.xlsx(readBifactor2PL_173_ResidualsLDG2, 
           file = "readBifactor2PL_173_ResidualsLDG2.xlsx", rowNames = TRUE)
```

#### Theta scores 
##### M = 0.0002, SD = 0.80
Central tendency characteristics
```{r}
Theta_read173<-
  fscores(readBifactor2PL_173,method="EAP", QMC=TRUE, 
          full.scores=TRUE,full.scores.SE=TRUE)
# Ensure the data is in a data frame format
Theta_read173 <- 
  data.frame(Theta_read173)
# Add the variable of DAACS_ID to the dataframe with thetas:
Theta_read173$DAACS_ID <- read.items_AnSamp1DAACS_ID_vector
# Rename the columns
names(Theta_read173)[1] <- "Theta_read173"
names(Theta_read173)[32] <- "SE_Theta_read173"
names(Theta_read173)
```


Save theta estimates to external file
```{r}
write.csv(Theta_read173,
          "Theta_read173.csv",quote=F,row.names=F)
# Calculate mean and standard deviation
mean_valueThetas_173 <- mean(Theta_read173$Theta_read173)
sd_valueThetas_173 <- sd(Theta_read173$Theta_read173)
mean_valueThetas_173 # 0002
sd_valueThetas_173 # 0.80
```

##### Histogram 
```{r}
# library(ggplot2)
# Function to create a histogram with legend and left-aligned footnote for SD
create_histogram <- function(data, variable, mean_value, sd_value, title_prefix, output_file) {
  # Convert the variable name to a symbol for dynamic use in ggplot2
  variable_sym <- rlang::sym(variable)
  
  # Ensure non-exponential format for mean and SD
  mean_str <- sprintf("%.4f", mean_value)
  mean_sd_minus_str <- sprintf("%.4f", mean_value - sd_value)
  mean_sd_plus_str <- sprintf("%.4f", mean_value + sd_value)
  sd_str <- sprintf("%.4f", sd_value)

  # Create the histogram
  hist_plot <- ggplot(data, aes(x = !!variable_sym)) +
    geom_histogram(
      binwidth = 0.5,
      fill = "lightblue",
      color = "black",
      alpha = 0.7
    ) +
    geom_vline(aes(xintercept = mean_value, color = "Mean"), 
               linetype = "dashed", size = 1) +
    geom_vline(aes(xintercept = mean_value + sd_value, color = "Mean + SD"), 
               linetype = "dotted", size = 1) +
    geom_vline(aes(xintercept = mean_value - sd_value, color = "Mean - SD"), 
               linetype = "dotted", size = 1) +
    scale_color_manual(
      name = NULL,  # Remove legend title
      values = c("Mean" = "black", "Mean - SD" = "black", "Mean + SD" = "black"),
      labels = c(
        paste0("Mean = ", mean_str),
        paste0("Mean - SD = ", mean_sd_minus_str),
        paste0("Mean + SD = ", mean_sd_plus_str)
      )
    ) +
    labs(
      title = paste0(title_prefix, " (n = ", nrow(data), ")"),
      x = variable,
      y = "Frequency",
      caption = paste0("SD = ", sd_str)  # Add left-aligned footnote for SD
    ) +
    theme_minimal() +
    theme(
      legend.position = c(0.35, 0.95), # Place legend in upper-right corner
      legend.justification = c("right", "top"),
      legend.background = element_blank(),  # No frame around legend
      legend.key = element_blank(),  # No key background
      plot.caption = element_text(hjust = 0, size = 10, face = "italic")  # Left-aligned footnote
    )
  
  # Save the plot as a PDF
  ggsave(
    filename = output_file,
    plot = hist_plot,
    width = 8,
    height = 6
  )
  
  # Display the plot inline in R Markdown or RStudio Plots pane
  hist_plot
}
# Example usage
ThetaR173_hist_AnSamp1<-create_histogram(
  data = Theta_read173,
  variable = "Theta_read173",
  mean_value = mean(Theta_read173$Theta_read173),
  sd_value = sd(Theta_read173$Theta_read173),
  title = "AnSamp1: Theta173 Scores" ,
  output_file = "ThetaR173_AnSamp1_histogram.pdf"
)
ThetaR173_hist_AnSamp1
```

##### Add the variable of Theta-scores to the datasets
```{r}
read.items_AnSamp1<-merge(read.items_AnSamp1,Theta_read180[,c("Theta_read180", "DAACS_ID")])
read.items_samp22D<-merge(read.items_samp22D,Theta_read180[,c("Theta_read180", "DAACS_ID")])
read.items_AnSamp2<-merge(read.items_AnSamp2,Theta_read180[,c("Theta_read180", "DAACS_ID")])
read.items_AnSamp1<-merge(read.items_AnSamp1,Theta_read173[,c("Theta_read173", "DAACS_ID")])
read.items_samp22D<-merge(read.items_samp22D,Theta_read173[,c("Theta_read173", "DAACS_ID")])
read.items_AnSamp2<-merge(read.items_AnSamp2,Theta_read173[,c("Theta_read173", "DAACS_ID")])
```

# Move the new variables of Theta-scores to the beginning of the datasets:
```{r}
read.items_AnSamp1<- read.items_AnSamp1[,c(1, 3:20, 202, 2, 21:201)]
read.items_samp22D<- read.items_samp22D[,c(1, 3:20, 202, 2, 21:201)]
read.items_AnSamp2<- read.items_AnSamp2[,c(1, 3:20, 202, 203,2, 21:201)]
```


##### Distributions of Theta-scores in two models (180 and 173)
```{r}
# Combine all Theta-scores in a single dataframe
Theta_read180<-as.data.frame(Theta_read180)
Theta_read173<-as.data.frame(Theta_read173)
readBifactor2PL_umgc1ua2_all_Thetas <-
  merge(Theta_read173[, c(1,32,63)],Theta_read180[, c(1,32,63)],all = T)
# Columns' names
names(readBifactor2PL_umgc1ua2_all_Thetas)
```

Rename the columns
```{r}
names(readBifactor2PL_umgc1ua2_all_Thetas)<- 
  c("DAACS_ID", "Theta_read173_AnSamp1","SE_Theta_read173_AnSamp1", "Theta_read180_AnSamp1", "SE_Theta_read180_AnSamp1")
names(readBifactor2PL_umgc1ua2_all_Thetas)
```

###### Density Plots of Theta-scores overlap fully 
```{r}
# Function to create two density plots of the correlated measures in a single chart
densityPlot_2corMeasures <- function(data1_tmp, data2_tmp, 
                                      label1_tmp = "Measure 1",
                                      label2_tmp = "Measure 2",
                                      x_label_tmp = "Values",
                                      footnote = "",
                                      output_file = "ReadingThetaScores_DensityPlot.pdf") {
  # Ensure both data vectors have the same length
  if (length(data1_tmp) != length(data2_tmp)) {
    stop("Both data vectors must have the same length.")
  }

  # Calculate statistics for each measure
  mean1 <- mean(data1_tmp, na.rm = TRUE)
  sd1 <- sd(data1_tmp, na.rm = TRUE)

  mean2 <- mean(data2_tmp, na.rm = TRUE)
  sd2 <- sd(data2_tmp, na.rm = TRUE)

  # Sample size
  n_samples <- length(data1_tmp)

  # Create the density plot
  density_plot <- ggplot() +
    # Density plot for data1_tmp
    geom_density(aes(x = data1_tmp, color = label1_tmp, fill = label1_tmp), 
                 alpha = 0.25, linewidth = 1) +
    # Density plot for data2_tmp
    geom_density(aes(x = data2_tmp, color = label2_tmp, fill = label2_tmp), 
                 alpha = 0.25, linewidth = 1) +
    # Add mean lines
    geom_vline(aes(xintercept = mean1, color = label1_tmp), 
               linetype = "dotted", linewidth = 1) +
    geom_vline(aes(xintercept = mean2, color = label2_tmp), 
               linetype = "dashed", linewidth = 1) +
    # Custom color and fill scales
    scale_color_manual(
      values = setNames(c("blue", "green"), c(label1_tmp, label2_tmp)),
      name = "Measures",
      labels = c(
        sprintf("%s (Mean = %.2f, SD = %.2f)", label1_tmp, mean1, sd1),
        sprintf("%s (Mean = %.2f, SD = %.2f)", label2_tmp, mean2, sd2)
      )
    ) +
    scale_fill_manual(
      values = setNames(c("blue", "green"), c(label1_tmp, label2_tmp)),
      guide = "none"
    ) +
    # Add title, labels, and footnote
    labs(
      title = sprintf("Density Plots for %s and %s (n = %d)", 
                      label1_tmp, label2_tmp, n_samples),
      x = x_label_tmp,
      y = "Density",
      caption = footnote
    ) +
    # Adjust theme for readability
    theme_minimal() +
    theme(
      legend.position = "top",
      legend.title = element_text(size = 12),
      legend.text = element_text(size = 10),
      plot.title = element_text(size = 14, face = "bold"),
      plot.caption = element_text(size = 9, hjust = 0)
    )

  # Display the plot
  print(density_plot)

  # Save the plot
  ggsave(output_file, plot = density_plot, width = 8, height = 6)
}

# Apply the function:
densityPlot_2corMeasures(
  data1_tmp = Theta_read180[, 1],
  data2_tmp = Theta_read173[, 1],
  label1_tmp = "Theta-scores from 180 Items",
  label2_tmp = "Theta-scores from 173 Items",
  x_label_tmp = "Theta-scores",
  footnote = 
  "Note: Data collected in 2022-23 a.y. from UMGC and UAlbany non-speedy students",
  output_file = "ReadingThetaScores_DensityPlot.pdf"
)
```

Note: The plot does not end abruptly at the right edge of the plot area. See the highest values of the Thetas.
```{r}
sort(Theta_read180$Theta_read180, decreasing = TRUE)[1:10]
sort(Theta_read173$Theta_read173, decreasing = TRUE)[1:10]
```

###### QQ tests: Theta-scores distributed closely to normal distribution
Both plots show a reasonable fit to a normal distribution, especially around
the central values. However, the tails deviate slightly from normality, which
might imply issues such as heavier tails or some skewness. This could suggest
that both models capture the central tendency well but might need refinement
in capturing extreme score behaviors.
```{r}
#library(car) 
readBifactor2PL_umgc1ua2_Theta180_qqPlot<-
  qqPlot(readBifactor2PL_umgc1ua2_all_Thetas$Theta_read180)
readBifactor2PL_umgc1ua2_Theta180_qqPlot
```

```{r}
readBifactor2PL_umgc1ua2_Thetas173_qqPlot<-
  qqPlot(readBifactor2PL_umgc1ua2_all_Thetas$Theta_read173)
readBifactor2PL_umgc1ua2_Thetas173_qqPlot
```

#### Shapiro-Wilk normality test for theta scores: p < 0.001
Theta_read is not normally distributed. 
```{r}
# Shapiro-Wilk normality test for each group
shapiro.test(read.items_AnSamp1$Theta_read173)
shapiro.test(read.items_AnSamp1$Theta_read180)
```


###### Paired-samples t-test confirms no difference in Theta-scores distributions 
To test whether the distributions of two Theta-scores are different using a pared-samples t-test:


```{r}
# Wide format needed: one row per student
t.test(read.items_AnSamp1$Theta_read180, read.items_AnSamp1$Theta_read173, paired = TRUE)
```

#### Parameters for 173 Reading Items (2PLModel-based) are better than for 180-items 
Warning message: Traditional parameterization (using IRTpars = TRUE) only 
available for unidimensional models or models with simple structure patterns 
(neither found)
```{r}
# \dontrun{} tmp<- coef(readBifactor2PL_173,
#             as.data.frame = TRUE, IRTpars = TRUE, printSE = TRUE)
```

```{r} 
# Extract parameters as a data frame 
readBifactor2PL_173_coeff <- 
  coef(readBifactor2PL_173, as.data.frame = TRUE, printSE = TRUE)
# Confirm the structure of 'readBifactor2PL_173_coeff'
str(readBifactor2PL_173_coeff)
# If not already a data frame, convert it explicitly
readBifactor2PL_173_coeff <- as.data.frame(readBifactor2PL_173_coeff)
# Round all numeric values to two decimal places
readBifactor2PL_173_coeff <- round(readBifactor2PL_173_coeff, 2)
str(readBifactor2PL_173_coeff)
# Filter out rows where 'par' is equal to 0
readBifactor2PL_173_coeff <- 
  readBifactor2PL_173_coeff[readBifactor2PL_173_coeff$par != 0, ,
                            drop = FALSE]  # Keep as a data frame
# Remove rows with any missing values
readBifactor2PL_173_coeff <- 
  readBifactor2PL_173_coeff[complete.cases(readBifactor2PL_173_coeff), ,
                            drop = FALSE]  # Ensure it's still a data frame
# Confirm the final structure
str(readBifactor2PL_173_coeff)
#Save the coefficients to external file:
write.csv(readBifactor2PL_173_coeff,
          "readBifactor2PL_173_coeff.csv",quote=F,row.names=T)
```

Parameters as a matrix 
Note. a = discrimination; d = intercept: It's the logit value which a person
with theta = 0 has of answering the item. So if d = 1, then plogis(1) = .73,
while if d = -1, then plogis(-1) = .26.
Total explained variance accounted for by the general factor is 64.9%
The proportion of explained common variance (ECV) provides an estimate of how
much variance in item responses is explained by the general factor, as opposed
to specific factors.
```{r} 
tmp<- coef(readBifactor2PL_173,as.data.frame = TRUE, printSE = TRUE)
tmp<-round(tmp, 2)
tmp <- subset(tmp[complete.cases(tmp),])
# Extract rownames based on the pattern
d_rows_tmp <- rownames(tmp[grep("\\.d$", rownames(tmp)), ])
aG_rows_tmp <- rownames(tmp[grep("\\.a1$", rownames(tmp)), ])
other_rows_tmp <- rownames(tmp[!(grepl("\\.d$|\\.a1$", rownames(tmp))), ])
# Create temporary data frames for each category
tmp_d <- tmp[d_rows_tmp, c("par", "SE")]
tmp_aG <- tmp[aG_rows_tmp, c("par", "SE")]
tmp_other <- tmp[other_rows_tmp, c("par", "SE")]
# Create the result matrix
result_matrix_tmp <- 
  matrix(NA,nrow=max(length(d_rows_tmp),length(aG_rows_tmp),
                     length(other_rows_tmp)),ncol=9)
rownames(result_matrix_tmp) <- 1:nrow(result_matrix_tmp)
# Fill the result matrix with data from temporary data frames
result_matrix_tmp[1:nrow(tmp_d), c(7, 8, 9)] <- cbind(d_rows_tmp, tmp_d)
result_matrix_tmp[1:nrow(tmp_aG), c(1, 2, 3)] <- cbind(aG_rows_tmp, tmp_aG)
result_matrix_tmp[1:nrow(tmp_other), c(4, 5, 6)] <- 
  cbind(other_rows_tmp, tmp_other)
# Sort the rows in each category
result_matrix_tmp <- result_matrix_tmp[order(result_matrix_tmp[, 1]), ]
colnames(result_matrix_tmp)<- c("qid","aG", "SE_aG",
                            "qid.a_testlet", "aS", "SE_aS",
                            "qid.d", "d", "SE_d")
# Print the resulting matrix
readBifactor2PL_173_Parameters<-print(result_matrix_tmp)
write.table(readBifactor2PL_173_Parameters,
            'readBifactor2PL_173_Parameters.csv',sep=',')
```

#### Total explained variance accounted for by the general factor is 64.9%
Extract Item aG-Parameters and calculate the variance accounted for the general 
factor by squaring the factor loadings. The squared loadings represent the 
proportion of each item's variance that is explained by the respective factor.
Sum the squared loadings for the general factor across all items to get the
total variance accounted for by the general factor. You can do the same for
each specific factor.
```{r} 
readBifactor2PL_173_Parameters_df<-
  as.data.frame(readBifactor2PL_173_Parameters)
numeric_cols_tmp <- c(2, 3, 5, 6, 8, 9) # to convert the loadings into numeric form
readBifactor2PL_173_Parameters_df[numeric_cols_tmp] <- 
  sapply(readBifactor2PL_173_Parameters_df[numeric_cols_tmp], as.numeric)
str(readBifactor2PL_173_Parameters_df)
readBifactor2PL_173_loadings<-readBifactor2PL_173_Parameters_df[,c(2,5)]
squared_loadings_tmp <- (readBifactor2PL_173_loadings)^2
general_factor_variance_tmp <- sum(squared_loadings_tmp[,1])
# Total variance (sum of squared loadings for all factors)
total_variance_tmp <- rowSums(squared_loadings_tmp)
# Proportion of Explained Common Variance (ECV)
ECVreadBifactor2PL_173 <- 
  general_factor_variance_tmp / sum(total_variance_tmp)
# Print the ECV
print(ECVreadBifactor2PL_173) # 0.6492509
```

#### Items' IRT Plots
```{r} 
# To see the plots in the plots pane only:
# Loop through each item, generate and display the plot
for(i in 1:173) {
  # Generate the plot
  readbifactor2PL_AnSamp1_173irtPlots <- 
    itemplot(readBifactor2PL_173, i, drop.zeros = TRUE)
  
  # Explicitly print the plot
  print(readbifactor2PL_AnSamp1_173irtPlots)
}

# To save the plots in a PDF file:
# Open a PDF file to save all plots
pdf("173 Reading Items IRT Plots_AnSamp1.pdf")

# Loop through each item and generate a plot
for(i in 1:173) {
  # Generate the plot
  # readbifactor2PL_AnSamp1_173irtPlots <- 
  # itemplot(readBifactor2PL_173, i, drop.zeros = TRUE)
  
  # Explicitly print the plot to the PDF
  print(readbifactor2PL_AnSamp1_173irtPlots)
}
# Close the PDF device
dev.off()
```

# Update the read.items_AnSamp1
```{r}
read.items_AnSamp1<-read.items_AnSamp1
```

# Save the environment 
```{r} 
#save.image("D:/Dropbox/DAACS-Validity/Analyses/Reading/read_dataClean-UMGC1UA2_2.RData")
save.image("C:/Users/orosc/OneDrive - University at Albany - SUNY/My DAACS/read/read_dataClean-UMGC1UA2_2.RData")

```